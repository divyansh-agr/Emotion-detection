{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEnQGOB31hq8"
      },
      "source": [
        "# Text Emotion Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7GTwCKRlfkB"
      },
      "outputs": [],
      "source": [
        "# Import Libraries for Project\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEIF2BlcmDmP"
      },
      "outputs": [],
      "source": [
        "# Load Dataset in csv format\n",
        "df=pd.read_csv('/content/emotion_dataset_raw.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjBtcfHanHU4"
      },
      "outputs": [],
      "source": [
        "# Print Top 5 Emotions from Dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_WhgZDInLAK"
      },
      "outputs": [],
      "source": [
        "# Count Number of Emotions\n",
        "df['Emotion'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kz9q7CSncGP"
      },
      "outputs": [],
      "source": [
        "# Plot Graph\n",
        "color_palette = sns.color_palette(\"pastel\")\n",
        "sns.set_palette(color_palette)\n",
        "sns.countplot(x='Emotion',data=df, hue='Emotion', legend=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BL2BBGa9oMi4"
      },
      "outputs": [],
      "source": [
        "!pip install neattext\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjlNBCg1p5jV"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "import neattext.functions as nfx\n",
        "\n",
        "# Remove the user handles\n",
        "df['Clean_Text'] = df['Text'].apply(nfx.remove_userhandles)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2sy_a_bqqK6"
      },
      "outputs": [],
      "source": [
        "dir(nfx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Tg05wqm-LB2"
      },
      "outputs": [],
      "source": [
        "# Splitting data into input variables and target variable\n",
        "# x : Features are the attributes and variables extracted from the dataset.These extracted features are used as inputs to the model during training.\n",
        "# y : Lables are the output or the target variable.\n",
        "x = df['Clean_Text']\n",
        "y = df['Emotion']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HryW1oiE_bE9"
      },
      "outputs": [],
      "source": [
        "# Splitting data into train and test set\n",
        "# we need to split our dataset into a train set and test set. The model will learn from the train set. We will use the test set to evaluate the model performance and measure the model's knowledge capability\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zOLGqfmAyeH"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create a pipeline with CountVectorized and LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_D_EirmDvNm"
      },
      "outputs": [],
      "source": [
        "pipe_lr = Pipeline(steps=[('cv',CountVectorizer()),('lr',LogisticRegression())])\n",
        "pipe_lr.fit(x_train,y_train)\n",
        "pipe_lr.score(x_test,y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d73tojc8FAxE"
      },
      "outputs": [],
      "source": [
        "pipe_rf = Pipeline(steps=[('cv',CountVectorizer()),('rf',RandomForestClassifier())])\n",
        "pipe_rf.fit(x_train,y_train)\n",
        "pipe_rf.score(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eOj3osQUpzp"
      },
      "outputs": [],
      "source": [
        "# Saving the model\n",
        "import joblib\n",
        "pipeline_file = open(\"text_emotion.pkl\",\"wb\")\n",
        "joblib.dump(pipe_lr,pipeline_file)\n",
        "pipeline_file.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
